# RAG LLM App: Indexing and Querying Multiple PDFs with LlamaIndex & HuggingFace
This application leverages LlamaIndex (formerly known as GPT Index) in combination with HuggingFace's transformers to create a Retrieval-Augmented Generation (RAG) system that can efficiently index and query multiple PDF documents. The app allows users to input multiple PDFs, which are then indexed and queried using large language models (LLMs), providing contextual answers to user queries based on the content of the uploaded documents.

## Features
- PDF Processing: Accepts multiple PDFs as input.
- Indexing: Uses LlamaIndex to create an efficient index of the text extracted from PDFs.
- Querying: Leverages LlamaIndex's capabilities to retrieve relevant passages from the indexed PDFs based on user queries.
- LLM Integration: Uses HuggingFace's transformer models to augment responses and provide coherent, context-aware answers.
- RAG Framework: Combines both retrieval and generation to ensure that the answers generated by the LLM are accurate and based on the provided data.
- User-Friendly: Simple to set up and extend with additional LLM models and data sources.
## How It Works
- Input: Users upload multiple PDFs.
- PDF Parsing: The PDFs are processed to extract raw text using libraries like PyPDF2 or pdfminer.
- Indexing: The extracted text is indexed using LlamaIndex, enabling fast look-up and retrieval based on user queries.
- Querying: Users can input queries, which the system uses to retrieve the most relevant information from the indexed documents.
- Response Generation: After retrieving the relevant information, HuggingFace's transformer models are used to generate a coherent, natural-language response.
##Getting Started
### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/RAG-LLM-App.git
cd RAG-LLM-App
```
### 2. Install Dependencies
You need the following Python libraries to run the app:

```bash
pip install llama-index
pip install transformers
pip install PyPDF2
pip install pdfminer.six
pip install torch
```
### 3. Run the Application
```bash
python app.py
```
## Main Components
### LlamaIndex:

Used to create an efficient index from the raw text extracted from PDF documents. It provides the core retrieval functionality, allowing the system to find relevant passages based on user queries.

### HuggingFace Transformers:

HuggingFace's pre-trained language models (e.g., GPT-3, BERT, etc.) are used to generate responses that are contextually relevant and coherent, augmenting the retrieval process with generative capabilities.

### PDF Processing:

PyPDF2: A lightweight library for extracting text from PDFs.
pdfminer.six: A more robust option for extracting structured text from PDFs, useful when dealing with complex or scanned documents.

## Optional Libraries
- Faiss: If you have a large set of documents, you can optionally use Faiss for efficient vector-based indexing and querying.
```bash
pip install faiss-cpu
```
## Example Usage
- Upload PDFs: Upload a collection of PDFs to the application.
- Indexing: The app will automatically parse and index the content.
- Query: Input any natural language query, and the system will retrieve the most relevant content from the PDFs and generate a response.
## Code Snippet
Here is a simplified version of how the core functionality might look:

```python
from llama_index import GPTSimpleVectorIndex, SimpleDirectoryReader
from transformers import pipeline

# Load PDFs and extract text
pdf_directory = "./pdfs"
reader = SimpleDirectoryReader(pdf_directory)
documents = reader.load_data()

# Index the documents
index = GPTSimpleVectorIndex(documents)

# Initialize HuggingFace model
nlp = pipeline('question-answering', model="distilbert-base-uncased-distilled-squad")

# Query the index
def query_documents(question):
    # Retrieve relevant info from index
    response = index.query(question)
    
    # Generate an answer using HuggingFace transformers
    result = nlp(question=question, context=response)
    return result['answer']

# Example query
answer = query_documents("What is the main conclusion of the research?")
print(answer)
```
## Future Enhancements
- UI Integration: Add a user-friendly web interface using Flask or Streamlit.
- Advanced PDF Parsing: Implement optical character recognition (OCR) for handling scanned PDFs using tools like Tesseract.
- Model Fine-Tuning: Fine-tune HuggingFace models to improve answer accuracy based on the specific document corpus.

## Libraries and Tools Overview
- LlamaIndex: Efficient indexing and querying of textual data.
- HuggingFace Transformers: Pre-trained models for advanced NLP tasks.
- PyPDF2: PDF text extraction.
pdfminer.six: Advanced PDF parsing.
- Torch: Required for running HuggingFace transformer models.
- Faiss (Optional): Fast indexing for large-scale document retrieval.

  
By using this RAG system, users can efficiently query large collections of PDFs and receive accurate, context-aware responses based on the content of those documents.
